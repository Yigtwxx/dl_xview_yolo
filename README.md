# ğŸ›°ï¸ DL_XVIEW â€¢ Object Detection in Satellite Imagery
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)
![YOLOv8](https://img.shields.io/badge/Model-YOLOv8-success.svg)
![Stars](https://img.shields.io/github/stars/Yigtwxx/dl_xview_yolo?style=social)


**Deep Learningâ€“based Object Detection** system for satellite imagery using **YOLOv8**.  
This project applies **state-of-the-art computer vision models** to detect objects such as airplanes, ships, vehicles, bridges, and more from aerial or satellite images.  
Data sources include **xView** and **DOTA** datasets.

>  Goal: Detect and classify multiple objects in high-resolution satellite imagery  
>  Model: YOLOv8 (with Oriented Bounding Box / OBB support)

---

##  Features

-  Object detection using YOLOv8 (Ultralytics)
-  Dataset conversion utilities for xView / DOTA â†’ YOLO format (`convert_all_to_yolo.py`)
-  Interactive web-based prediction UI (`ui/index.html`)
-  Utility scripts: `train_yolo.py`, `predict_yolo.py`, `summarize_run.py`
-  Easy path and parameter customization

## ğŸ—‚ï¸ Project Structure
```text
dl_xview_yolo/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_all_to_yolo.py     # Converts datasets to YOLO format
â”‚   â”œâ”€â”€ train_yolo.py              # Training script
â”‚   â”œâ”€â”€ predict_yolo.py            # Inference script
â”‚   â”œâ”€â”€ summarize_run.py           # Summarizes training metrics
â”‚   â””â”€â”€ prepare_dota_v1_to_yolo_obb.py
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ index.html                 # Interactive front-end for predictions
â”‚
â”œâ”€â”€ YOLOv8/                        # YOLOv8 models / configs
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Environment Preparation

> Recommended: Python 3.10 or higher

```bash
git clone https://github.com/Yigtwxx/dl_xview_yolo.git
cd dl_xview_yolo
python -m venv venv
venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

If you donâ€™t have a `requirements.txt` file, install manually:

```bash
pip install ultralytics opencv-python pillow tqdm numpy torch torchvision torchaudio matplotlib
```

---

##  Dataset Preparation

### 1ï¸âƒ£ Supported Datasets

* [xView Dataset](https://challenge.xviewdataset.org/)
* [DOTA Dataset](https://captain-whu.github.io/DOTA/)

### 2ï¸âƒ£ Convert to YOLO Format

```bash
python scripts/convert_all_to_yolo.py --src "data/raw" --out "data/yolo_data" --copy
```

**Explanation:**

* Converts raw `.txt` annotations into YOLO-style labels
* Saves output to `data/yolo_data`
* Copies images when `--copy` flag is used

---

##  Training

```bash
python scripts/train_yolo.py --data "configs/data.yaml" --model "yolov8n.pt" --epochs 40 --imgsz 1024
```

* Model checkpoints are saved under `runs/train/...`
* You can monitor metrics via `results.png` (mAP, loss curves, etc.)

---

##  Inference

### Command Line

```bash
python scripts/predict_yolo.py --weights "runs/train/xview-yolo/weights/best.pt" --source "data/test_images"
```

### Web UI

```bash
# If integrated with FastAPI / Streamlit UI:
python scripts/predict_yolo.py --ui
```

Then open your browser at
ğŸ‘‰ **[http://127.0.0.1:7860/](http://127.0.0.1:7860/)**

---

## ğŸ¨ User Interface (UI)

Open `ui/index.html` directly in your browser to visualize predictions.

> ğŸ’« Modern design: world-themed background & glass-panel overlay
> ğŸ“‚ Upload: drag-and-drop or select image
> ğŸ§  Backend: connects directly to YOLOv8 model for real-time inference

---

## ğŸ“Š Example Results

| Metric       | Value |
| ------------ | ----- |
| mAP@0.5      | 0.54  |
| mAP@0.5-0.95 | 0.36  |
| Precision    | 0.67  |
| Recall       | 0.71  |

> *Metrics may vary depending on dataset and training configuration.*
> See `runs/train/.../results.png` for detailed training graphs.

---

## ğŸ“¦ Model Weights

If your trained model (`best.pt`) is smaller than 100 MB, you can store it in:

```
runs/train/xview-yolo/weights/best.pt
```

Otherwise, upload to Google Drive and link it here:

```
[ğŸ“ Download best.pt](https://drive.google.com/your-model-link)
```

---

## ğŸ§© Requirements

* ğŸ§  Python â‰¥ 3.10
* âš¡ PyTorch â‰¥ 2.0
* ğŸ¯ Ultralytics YOLOv8
* ğŸ“¸ OpenCV, Pillow
* ğŸ“Š Matplotlib

---

## âš ï¸ Notes

* Training datasets (`data/`, `runs/`, `venv/`) are excluded from Git using `.gitignore`.
* To resume training from the last checkpoint:

```bash
python scripts/train_yolo.py --resume
```

---

## ğŸ“œ License

This project is licensed under the **MIT License**.
See the [LICENSE](LICENSE) file for details.

---

## ğŸ’¬ Author

**YiÄŸit ErdoÄŸan (Yigtwxx)**
ğŸ“§ [yigiterdogan6@icloud.com](mailto:yigiterdogan6@icloud.com)
ğŸ§  Focus Areas: Deep Learning â€¢ Computer Vision â€¢ Data Science

---

## â­ Support

If you find this project useful, please consider giving it a **â­ Star** on GitHub!

ğŸŒ **Live Project Page:** [https://yigtwxx.github.io/dl_xview_yolo](https://yigtwxx.github.io/dl_xview_yolo)


```bash
git clone https://github.com/Yigtwxx/dl_xview_yolo.git
```
